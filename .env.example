# LLM Translation Service Environment Configuration
# Copy this file to .env and modify as needed

# Application Environment
ENVIRONMENT=development
DEBUG=true

# Deployment Mode (local for same machine, remote for different networks)
DEPLOYMENT__MODE=local
DEPLOYMENT__SERVICE_NAME=llm-translation-local
DEPLOYMENT__NETWORK_INTERFACE=auto
DEPLOYMENT__ENABLE_DISCOVERY=false

# API Configuration
API__HOST=127.0.0.1
API__PORT=9000
API__TITLE="LLM Translation Service"
API__DESCRIPTION="Local LLM-powered translation service with Baidu API compatibility"
API__VERSION="1.0.0"

# Ollama Configuration
OLLAMA__OLLAMA_HOST=http://localhost:11434
OLLAMA__MODEL_NAME=llava:latest

# Redis Configuration (optional for caching)
REDIS__REDIS_URL=redis://localhost:6379/0

# Authentication (disable for local development)
AUTH__DISABLE_SIGNATURE_VALIDATION=true

# Logging
LOGGING__LOG_LEVEL=INFO
