# Remote deployment configuration
# Use this for production when llmYTranslate is on a different machine/network

# Deployment Mode
DEPLOYMENT__MODE=remote
DEPLOYMENT__SERVICE_NAME=llm-translation-remote
DEPLOYMENT__NETWORK_INTERFACE=auto
DEPLOYMENT__ENABLE_DISCOVERY=true
DEPLOYMENT__DISCOVERY_PORT=8889
DEPLOYMENT__EXTERNAL_HOST=your-external-ip-or-domain
DEPLOYMENT__EXTERNAL_PORT=8888

# API Configuration (bind to all interfaces for remote access)
API__HOST=0.0.0.0
API__PORT=8888

# CORS (more permissive for remote access)
API__CORS_ORIGINS=["*"]

# Ollama Configuration (could be local or remote)
OLLAMA__OLLAMA_HOST=http://localhost:11434
OLLAMA__MODEL_NAME=llava:latest

# Redis Configuration
REDIS__REDIS_URL=redis://localhost:6379/0

# Authentication (enable for production)
AUTH__DISABLE_SIGNATURE_VALIDATION=false
AUTH__SECRET_KEY=your-production-secret-key-change-this

# Environment
ENVIRONMENT=production
DEBUG=false

# Logging
LOGGING__LOG_LEVEL=INFO

# Rate Limiting (stricter for remote access)
RATE_LIMIT__REQUESTS_PER_MINUTE=30
RATE_LIMIT__REQUESTS_PER_HOUR=500
RATE_LIMIT__REQUESTS_PER_DAY=5000
